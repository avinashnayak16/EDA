{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a42646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor - MAE: 64.86645567836328, MSE: 6325.89259977429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avina\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15856.6758 - mae: 92.1368 - val_loss: 9019.3672 - val_mae: 82.4935\n",
      "Epoch 2/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8574.7637 - mae: 76.7629 - val_loss: 6700.2729 - val_mae: 68.4711\n",
      "Epoch 3/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6884.9878 - mae: 64.2058 - val_loss: 6432.4082 - val_mae: 65.6057\n",
      "Epoch 4/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6852.2939 - mae: 63.9156 - val_loss: 6331.0718 - val_mae: 64.0100\n",
      "Epoch 5/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6863.8838 - mae: 63.3560 - val_loss: 6646.0571 - val_mae: 66.6480\n",
      "Epoch 6/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6846.6709 - mae: 63.2922 - val_loss: 6380.7964 - val_mae: 64.0199\n",
      "Epoch 7/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6645.9409 - mae: 61.9381 - val_loss: 6747.1284 - val_mae: 67.4655\n",
      "Epoch 8/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6661.3301 - mae: 62.6858 - val_loss: 6525.9336 - val_mae: 66.5228\n",
      "Epoch 9/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6725.8008 - mae: 62.3866 - val_loss: 6473.3228 - val_mae: 65.0846\n",
      "Epoch 10/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6570.2275 - mae: 61.6683 - val_loss: 6500.6479 - val_mae: 65.8453\n",
      "Epoch 11/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6675.5161 - mae: 62.7609 - val_loss: 6314.4712 - val_mae: 63.2179\n",
      "Epoch 12/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6505.4033 - mae: 61.1745 - val_loss: 6523.0986 - val_mae: 63.8414\n",
      "Epoch 13/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6467.3379 - mae: 61.1121 - val_loss: 6372.4927 - val_mae: 64.2409\n",
      "Epoch 14/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6562.6689 - mae: 61.9499 - val_loss: 6364.8110 - val_mae: 64.0380\n",
      "Epoch 15/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6480.8682 - mae: 61.1000 - val_loss: 6496.5859 - val_mae: 64.6542\n",
      "Epoch 16/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6543.6104 - mae: 61.4364 - val_loss: 6386.6704 - val_mae: 63.9988\n",
      "Epoch 17/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6555.4717 - mae: 61.5394 - val_loss: 6676.4194 - val_mae: 65.0139\n",
      "Epoch 18/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6419.3057 - mae: 60.9823 - val_loss: 6576.5581 - val_mae: 63.8122\n",
      "Epoch 19/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6596.9390 - mae: 61.4517 - val_loss: 6289.4897 - val_mae: 62.7239\n",
      "Epoch 20/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6396.3994 - mae: 60.8584 - val_loss: 6415.9326 - val_mae: 64.3741\n",
      "Epoch 21/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6437.2515 - mae: 61.1045 - val_loss: 6476.8135 - val_mae: 62.1766\n",
      "Epoch 22/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6461.0093 - mae: 61.0742 - val_loss: 6648.7095 - val_mae: 64.8443\n",
      "Epoch 23/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6369.0088 - mae: 60.1293 - val_loss: 6545.1040 - val_mae: 65.9921\n",
      "Epoch 24/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6217.6074 - mae: 59.8757 - val_loss: 6597.3765 - val_mae: 65.9984\n",
      "Epoch 25/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6310.5342 - mae: 60.1677 - val_loss: 6498.1465 - val_mae: 64.9399\n",
      "Epoch 26/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6317.6626 - mae: 60.1731 - val_loss: 6568.4482 - val_mae: 63.8054\n",
      "Epoch 27/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6022.6006 - mae: 58.8042 - val_loss: 6676.4937 - val_mae: 63.5240\n",
      "Epoch 28/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6202.2935 - mae: 59.7123 - val_loss: 6498.9556 - val_mae: 63.1146\n",
      "Epoch 29/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6209.7192 - mae: 59.3451 - val_loss: 6753.5220 - val_mae: 65.6369\n",
      "Epoch 30/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6133.8989 - mae: 59.2850 - val_loss: 6646.4761 - val_mae: 64.8736\n",
      "Epoch 31/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6194.6904 - mae: 59.1089 - val_loss: 6474.5205 - val_mae: 64.3541\n",
      "Epoch 32/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6006.6743 - mae: 58.7228 - val_loss: 6803.9961 - val_mae: 65.6155\n",
      "Epoch 33/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5951.4346 - mae: 58.6285 - val_loss: 6760.5200 - val_mae: 64.3601\n",
      "Epoch 34/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6211.2769 - mae: 59.7116 - val_loss: 6386.0806 - val_mae: 60.4652\n",
      "Epoch 35/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6039.6045 - mae: 58.7095 - val_loss: 6546.1724 - val_mae: 64.2529\n",
      "Epoch 36/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6100.6880 - mae: 58.9330 - val_loss: 6615.6216 - val_mae: 63.2702\n",
      "Epoch 37/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5922.4302 - mae: 57.9513 - val_loss: 6428.1836 - val_mae: 62.7720\n",
      "Epoch 38/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5978.1533 - mae: 58.5437 - val_loss: 7116.0869 - val_mae: 66.9060\n",
      "Epoch 39/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5997.0640 - mae: 58.3870 - val_loss: 6965.2905 - val_mae: 66.0239\n",
      "Epoch 40/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6073.6392 - mae: 58.4580 - val_loss: 6602.4106 - val_mae: 65.7238\n",
      "Epoch 41/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6005.0581 - mae: 58.2082 - val_loss: 6785.9697 - val_mae: 64.2633\n",
      "Epoch 42/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5794.3350 - mae: 57.0844 - val_loss: 6595.5708 - val_mae: 64.5024\n",
      "Epoch 43/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5799.0474 - mae: 57.4260 - val_loss: 6710.4478 - val_mae: 65.4106\n",
      "Epoch 44/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5870.6567 - mae: 58.1195 - val_loss: 6753.5391 - val_mae: 62.0674\n",
      "Epoch 45/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5871.9907 - mae: 57.5937 - val_loss: 6695.4985 - val_mae: 65.9105\n",
      "Epoch 46/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5635.5190 - mae: 56.5291 - val_loss: 6660.7158 - val_mae: 63.1139\n",
      "Epoch 47/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5793.3276 - mae: 57.0962 - val_loss: 7069.8564 - val_mae: 64.8572\n",
      "Epoch 48/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5662.0815 - mae: 56.6318 - val_loss: 6692.2251 - val_mae: 65.9570\n",
      "Epoch 49/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5740.6323 - mae: 56.7888 - val_loss: 6948.1851 - val_mae: 67.6694\n",
      "Epoch 50/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5571.9600 - mae: 56.0611 - val_loss: 6976.4639 - val_mae: 65.3636\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5778.9912 - mae: 57.1664 - val_loss: 7355.0186 - val_mae: 68.9305\n",
      "Epoch 52/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5583.0684 - mae: 55.5477 - val_loss: 6978.8813 - val_mae: 66.2877\n",
      "Epoch 53/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5683.3154 - mae: 56.8756 - val_loss: 6796.2192 - val_mae: 64.7122\n",
      "Epoch 54/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5508.1187 - mae: 55.9369 - val_loss: 7075.6069 - val_mae: 63.8120\n",
      "Epoch 55/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5428.6719 - mae: 55.1839 - val_loss: 6990.5347 - val_mae: 65.9679\n",
      "Epoch 56/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5460.7549 - mae: 55.5136 - val_loss: 7011.6860 - val_mae: 65.1440\n",
      "Epoch 57/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5297.4062 - mae: 54.8531 - val_loss: 6818.2686 - val_mae: 65.8371\n",
      "Epoch 58/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5529.3188 - mae: 55.9945 - val_loss: 7032.1597 - val_mae: 64.6518\n",
      "Epoch 59/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5383.7427 - mae: 55.6925 - val_loss: 6999.0469 - val_mae: 67.0003\n",
      "Epoch 60/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5276.4878 - mae: 54.6062 - val_loss: 7114.7178 - val_mae: 66.3322\n",
      "Epoch 61/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5360.9038 - mae: 55.2625 - val_loss: 7145.0659 - val_mae: 65.3029\n",
      "Epoch 62/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5334.4253 - mae: 54.9558 - val_loss: 7622.0542 - val_mae: 68.6752\n",
      "Epoch 63/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5337.0225 - mae: 54.8075 - val_loss: 7556.5137 - val_mae: 68.1492\n",
      "Epoch 64/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5248.4028 - mae: 54.5462 - val_loss: 7332.3989 - val_mae: 66.8815\n",
      "Epoch 65/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5169.2695 - mae: 54.1183 - val_loss: 7476.9946 - val_mae: 67.2631\n",
      "Epoch 66/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5303.2939 - mae: 54.6147 - val_loss: 7611.8354 - val_mae: 69.0961\n",
      "Epoch 67/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5133.8496 - mae: 53.9947 - val_loss: 7220.0859 - val_mae: 64.6683\n",
      "Epoch 68/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5190.7568 - mae: 54.2281 - val_loss: 7404.6592 - val_mae: 67.5397\n",
      "Epoch 69/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5219.0068 - mae: 54.3645 - val_loss: 7155.2734 - val_mae: 67.2696\n",
      "Epoch 70/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5131.0103 - mae: 54.0650 - val_loss: 7204.4834 - val_mae: 65.6485\n",
      "Epoch 71/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5232.3408 - mae: 54.4616 - val_loss: 7146.6948 - val_mae: 66.6037\n",
      "Epoch 72/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4867.9966 - mae: 52.3572 - val_loss: 7439.7427 - val_mae: 67.4665\n",
      "Epoch 73/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4988.5332 - mae: 53.3425 - val_loss: 7770.0522 - val_mae: 66.4428\n",
      "Epoch 74/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5049.3413 - mae: 53.7488 - val_loss: 7252.9995 - val_mae: 66.7232\n",
      "Epoch 75/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5049.5562 - mae: 53.3575 - val_loss: 7552.4727 - val_mae: 68.8901\n",
      "Epoch 76/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5045.1152 - mae: 53.8992 - val_loss: 7396.3359 - val_mae: 64.4491\n",
      "Epoch 77/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4955.5679 - mae: 52.9328 - val_loss: 7074.8359 - val_mae: 65.0410\n",
      "Epoch 78/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4820.0488 - mae: 52.1322 - val_loss: 7433.0015 - val_mae: 65.2786\n",
      "Epoch 79/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5009.0811 - mae: 52.8992 - val_loss: 7521.0986 - val_mae: 68.8233\n",
      "Epoch 80/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4911.8042 - mae: 52.7600 - val_loss: 7534.7715 - val_mae: 65.4123\n",
      "Epoch 81/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4752.7881 - mae: 51.7253 - val_loss: 7615.4414 - val_mae: 68.0747\n",
      "Epoch 82/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4827.8960 - mae: 52.2785 - val_loss: 7523.4165 - val_mae: 66.7747\n",
      "Epoch 83/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4702.1606 - mae: 51.6803 - val_loss: 7680.3145 - val_mae: 69.1276\n",
      "Epoch 84/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4811.4829 - mae: 52.3284 - val_loss: 7665.7305 - val_mae: 69.1754\n",
      "Epoch 85/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4692.8530 - mae: 51.6882 - val_loss: 7976.4829 - val_mae: 71.0315\n",
      "Epoch 86/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4788.4805 - mae: 52.3477 - val_loss: 7432.0469 - val_mae: 66.7863\n",
      "Epoch 87/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4735.9404 - mae: 51.8179 - val_loss: 7687.3057 - val_mae: 66.3339\n",
      "Epoch 88/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4659.4043 - mae: 50.9953 - val_loss: 7694.7876 - val_mae: 66.6241\n",
      "Epoch 89/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4537.1455 - mae: 50.7876 - val_loss: 8468.4346 - val_mae: 71.4976\n",
      "Epoch 90/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4584.4141 - mae: 51.0411 - val_loss: 8392.6211 - val_mae: 69.3799\n",
      "Epoch 91/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4694.7236 - mae: 51.5147 - val_loss: 8485.1797 - val_mae: 70.7203\n",
      "Epoch 92/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4690.2847 - mae: 51.7790 - val_loss: 7934.7607 - val_mae: 66.4765\n",
      "Epoch 93/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4679.6709 - mae: 51.2777 - val_loss: 7495.8062 - val_mae: 67.8299\n",
      "Epoch 94/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4600.2788 - mae: 51.0371 - val_loss: 7950.9648 - val_mae: 69.6444\n",
      "Epoch 95/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4521.5952 - mae: 50.3886 - val_loss: 8029.7529 - val_mae: 69.3530\n",
      "Epoch 96/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4591.5601 - mae: 51.0467 - val_loss: 7924.5918 - val_mae: 70.0189\n",
      "Epoch 97/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4417.3867 - mae: 50.0473 - val_loss: 8422.1074 - val_mae: 70.8467\n",
      "Epoch 98/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4655.8730 - mae: 51.2613 - val_loss: 7748.7593 - val_mae: 68.2449\n",
      "Epoch 99/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4406.6826 - mae: 49.8502 - val_loss: 7997.9033 - val_mae: 69.1702\n",
      "Epoch 100/100\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4322.7969 - mae: 49.5307 - val_loss: 8024.8740 - val_mae: 69.1071\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Neural Network - MAE: 69.10706404393369, MSE: 8024.873175514926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_data.drop(columns=['metastatic_diagnosis_period'])\n",
    "y_train = train_data['metastatic_diagnosis_period']\n",
    "X_test = test_data\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "numeric_cols = X_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Define preprocessing for numeric and categorical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Split the training data for validation\n",
    "X_train_part, X_val, y_train_part, y_val = train_test_split(X_train_processed, y_train, test_size=0.01, random_state=42)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gbr.fit(X_train_part, y_train_part)\n",
    "\n",
    "# Evaluation\n",
    "y_val_pred_gbr = gbr.predict(X_val)\n",
    "mae_gbr = mean_absolute_error(y_val, y_val_pred_gbr)\n",
    "mse_gbr = mean_squared_error(y_val, y_val_pred_gbr)\n",
    "print(f'Gradient Boosting Regressor - MAE: {mae_gbr}, MSE: {mse_gbr}')\n",
    "\n",
    "# Neural Network using TensorFlow\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_processed.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(X_train_part, y_train_part, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluation\n",
    "y_val_pred_nn = model.predict(X_val)\n",
    "mae_nn = mean_absolute_error(y_val, y_val_pred_nn)\n",
    "mse_nn = mean_squared_error(y_val, y_val_pred_nn)\n",
    "print(f'Neural Network - MAE: {mae_nn}, MSE: {mse_nn}')\n",
    "\n",
    "# Predict on test data using both models\n",
    "y_test_pred_gbr = gbr.predict(X_test_processed)\n",
    "y_test_pred_nn = model.predict(X_test_processed)\n",
    "\n",
    "# Save the predictions\n",
    "test_data['metastatic_diagnosis_period_pred_gbr'] = y_test_pred_gbr\n",
    "test_data['metastatic_diagnosis_period_pred_nn'] = y_test_pred_nn\n",
    "\n",
    "test_data.to_csv('test_data_with_predictions.csv', index=False)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "data=pd.read_csv(\"test_data_with_predictions.csv\")\n",
    "df[\"patient_id\"]=data[\"patient_id\"]\n",
    "df[\"metastatic_diagnosis_period\"]=data[\"metastatic_diagnosis_period_pred_gbr\"]\n",
    "df.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb51bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
